{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import unicodedata as ud\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "import csv\n",
    "from itertools import izip\n",
    "import HTMLParser\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1: positive, -1: negative, 0: neutral, 2: mixed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:38:08-05:00</td>\n",
       "      <td>Insidious!&lt;e&gt;Mitt Romney&lt;/e&gt;'s Bain Helped Phi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:14:18-05:00</td>\n",
       "      <td>.@WardBrenda @shortwave8669 @allanbourdius you...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:27:16-05:00</td>\n",
       "      <td>&lt;e&gt;Mitt Romney&lt;/e&gt; still doesn't &lt;a&gt;believe&lt;/a...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:11:43-05:00</td>\n",
       "      <td>&lt;e&gt;Romney&lt;/e&gt;'s &lt;a&gt;tax plan&lt;/a&gt; deserves a 2nd...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date            time  \\\n",
       "0                  NaN             NaN   \n",
       "1  2012-10-16 00:00:00  09:38:08-05:00   \n",
       "2  2012-10-16 00:00:00  10:14:18-05:00   \n",
       "3  2012-10-16 00:00:00  09:27:16-05:00   \n",
       "4  2012-10-16 00:00:00  10:11:43-05:00   \n",
       "\n",
       "                                     Anootated tweet  Class  \n",
       "0    1: positive, -1: negative, 0: neutral, 2: mixed    NaN  \n",
       "1  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...   -1.0  \n",
       "2  .@WardBrenda @shortwave8669 @allanbourdius you...   -1.0  \n",
       "3  <e>Mitt Romney</e> still doesn't <a>believe</a...   -1.0  \n",
       "4  <e>Romney</e>'s <a>tax plan</a> deserves a 2nd...   -1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"C:\\\\Users\\\\swapnil sagar\\\\Documents\\\\UIC\\\\Data mining\\\\project 2\\\\romneyTweets_Filtered.xlsx\");\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotatedTweet = data['Anootated tweet']\n",
    "actualClass = data['Class']\n",
    "lengthObama = len(data);\n",
    "\n",
    "annotatedTweet = annotatedTweet.drop(0)\n",
    "actualClass = actualClass.drop(0)\n",
    "\n",
    "\n",
    "annotatedTweetList = annotatedTweet.tolist();\n",
    "actualClassList = actualClass.tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0;\n",
    "\n",
    "finalFilteredTweet = []\n",
    "\n",
    "def removeStopWords(tweet):\n",
    "    filtered_tweet = [];\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'));\n",
    "    word_tokens = word_tokenize(tweet);\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tweet.append(w);\n",
    "    \n",
    "    eachTweet = \" \".join(filtered_tweet)  \n",
    "    return eachTweet\n",
    "    \n",
    "    \n",
    "def preProcessTweets(annotatedTweet):\n",
    "        \n",
    "        #remove links\n",
    "        processedTweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', annotatedTweet);\n",
    "        #remove references with @<word>\n",
    "        processedTweet = re.sub(r'(\\s)@\\w+', r'', processedTweet)\n",
    "        processedTweet = re.sub(r'@\\w+', r'', processedTweet)\n",
    "        \n",
    "        # remove HTML tags from tweet\n",
    "        processedTweet = re.sub('<[^<]+?>', '', processedTweet)\n",
    "        \n",
    "        #remove exclamation marks - hashtags should be removed?\n",
    "        processedTweet = re.sub(r'[<>!#@$:,%\\?-]+', r' ', processedTweet)\n",
    "        processedTweet = re.sub(r'[.]+', r'', processedTweet)\n",
    "        \n",
    "        #processedTweet = re.sub(r'(\\s)#\\w+', r'', processedTweet)\n",
    "        #processedTweet = re.sub(r'#\\w+', r'', processedTweet)\n",
    "        \n",
    "        # remove extra white spaces\n",
    "        processedTweet = re.sub(r'\\s+', r' ', processedTweet)\n",
    "        \n",
    "        #remove \"\" \n",
    "        processedTweet = processedTweet.replace('\"', '');\n",
    "        \n",
    "        processedTweet = ''.join([i if ord(i) < 128 else ' ' for i in processedTweet])\n",
    "\n",
    "        #stemming\n",
    "        stemmer = porterStemmer()\n",
    "        stemmedTweet = [stemmer.stem(word) for word in processedTweet.split(\" \")]\n",
    "        stemmedTweet = \" \".join(stemmedTweet)\n",
    "        processedTweet = str(stemmedTweet);\n",
    "        \n",
    "        processedTweet = processedTweet.replace(\"'\", \"\");\n",
    "\n",
    "        #remove numbers from data\n",
    "        #join\n",
    "        #processedTweet = \" \".join(re.findall('[A-Z][^A-Z]*', processedTweet));\n",
    "\n",
    "        #processedTweet = removeStopWords(processedTweet); --- Remove stop words in the end\n",
    "        \n",
    "        return processedTweet;\n",
    "\n",
    "    \n",
    "for every_tweet in annotatedTweetList:\n",
    "    \n",
    "    count = count +1     \n",
    "    tweet = preProcessTweets(every_tweet).encode('ascii', 'ignore').strip();\n",
    "    #print type(tweet)\n",
    "\n",
    "    finalFilteredTweet.append(tweet);        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5648"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalFilteredTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insidi mitt romney bain help philip morri get US high schooler hook On cigarett via',\n",
       " 'you mean like romney cheat in primari',\n",
       " 'mitt romney still doesnt believ that we have a black presid']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalFilteredTweet[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData, testTrainData , y_train, y_test = train_test_split(finalFilteredTweet, actualClassList, test_size = 0.15, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainData)\n",
    "len(testTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.00125,\n",
    "                             max_df = 0.70,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True,\n",
    "                            stop_words=u'english',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1,6),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(trainData);\n",
    "test_vectors = vectorizer.transform(testTrainData);\n",
    "total_vectors = vectorizer.fit_transform(finalFilteredTweet);\n",
    "\n",
    "#knn = KNeighborsClassifier()\n",
    "classifier_sgd = MultinomialNB()\n",
    "#classifier_sgd = linear_model.SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_sgd.fit(train_vectors, y_train)\n",
    "#knn.fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57193396226415094"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = classifier_sgd.predict(test_vectors)\n",
    "#predicted_labels = knn.predict(test_vectors)\n",
    "predicted_labelsList = predicted_labels.tolist();\n",
    "classifier_sgd.score(test_vectors, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.58      0.90      0.70       425\n",
      "          0       0.50      0.24      0.32       252\n",
      "          1       0.63      0.26      0.37       171\n",
      "\n",
      "avg / total       0.57      0.57      0.52       848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_classifiers = ['-1', '0', '1']\n",
    "print(classification_report(y_test, predicted_labelsList, target_names=target_classifiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54506752  0.49450755  0.48822592  0.53298344  0.52569857  0.5614167\n",
      "  0.56821684  0.49546279  0.51838427  0.52454748]\n"
     ]
    }
   ],
   "source": [
    "cvScores = cross_val_score(classifier_sgd, total_vectors, actualClassList, cv=10,scoring='f1_weighted')\n",
    "print (cvScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean: ', 0.52545111057288951)\n",
      "('Minimum: ', 0.48822592489503619)\n",
      "('Maximum: ', 0.56821684366125014)\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean: \", cvScores.mean())\n",
    "print (\"Minimum: \", cvScores.min())\n",
    "print (\"Maximum: \", cvScores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1. ..., -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "cvPredict = cross_val_predict(classifier_sgd, total_vectors, actualClassList, cv=10)\n",
    "print (cvPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.59      0.86      0.70      2893\n",
      "        0.0       0.45      0.24      0.32      1680\n",
      "        1.0       0.60      0.29      0.39      1075\n",
      "\n",
      "avg / total       0.55      0.57      0.53      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(actualClassList,cvPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdt = AdaBoostClassifier(classifier_sgd,\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          learning_rate=1.0, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdt.fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.518846590786\n"
     ]
    }
   ],
   "source": [
    "cvScores = cross_val_score(bdt, total_vectors, actualClassList, cv=10,scoring='f1_weighted')\n",
    "print (cvScores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. -1. ...,  0. -1.  0.]\n"
     ]
    }
   ],
   "source": [
    "cvPredict = cross_val_predict(bdt, total_vectors, actualClassList, cv=10)\n",
    "print (cvPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.61      0.69      0.65      2893\n",
      "        0.0       0.39      0.36      0.38      1680\n",
      "        1.0       0.50      0.37      0.42      1075\n",
      "\n",
      "avg / total       0.52      0.53      0.52      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(actualClassList,cvPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517680398984\n"
     ]
    }
   ],
   "source": [
    "cvScores = cross_val_score(clf, total_vectors, actualClassList, cv=10,scoring='f1_weighted')\n",
    "print (cvScores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ..., -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "cvPredict = cross_val_predict(clf, total_vectors, actualClassList, cv=10)\n",
    "print (cvPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.60      0.78      0.68      2893\n",
      "        0.0       0.41      0.31      0.35      1680\n",
      "        1.0       0.49      0.30      0.37      1075\n",
      "\n",
      "avg / total       0.52      0.55      0.52      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(actualClassList,cvPredict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
